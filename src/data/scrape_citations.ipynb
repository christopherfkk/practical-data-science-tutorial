{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gspread in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.11.3)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gspread) (2.23.2)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gspread) (1.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.12.0->gspread) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.12.0->gspread) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.12.0->gspread) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oauth2client in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.1.3)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from oauth2client) (0.22.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from oauth2client) (0.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from oauth2client) (0.3.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from oauth2client) (4.9)\n",
      "Requirement already satisfied: six>=1.6.1 in c:\\users\\cathe\\appdata\\roaming\\python\\python310\\site-packages (from oauth2client) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httplib2>=0.9.1->oauth2client) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install oauth2client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scholarly in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.11)\n",
      "Requirement already satisfied: arrow in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (4.12.2)\n",
      "Requirement already satisfied: bibtexparser in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (1.4.1)\n",
      "Requirement already satisfied: deprecated in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (1.2.14)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (1.2.1)\n",
      "Requirement already satisfied: free-proxy in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (1.1.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (1.0.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (2.31.0)\n",
      "Requirement already satisfied: selenium in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (4.13.0)\n",
      "Requirement already satisfied: sphinx-rtd-theme in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scholarly) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\users\\cathe\\appdata\\roaming\\python\\python310\\site-packages (from arrow->scholarly) (2.8.2)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arrow->scholarly) (2.8.19.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->scholarly) (2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bibtexparser->scholarly) (3.1.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from deprecated->scholarly) (1.15.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from free-proxy->scholarly) (4.9.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->scholarly) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->scholarly) (0.18.0)\n",
      "Requirement already satisfied: idna in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->scholarly) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->scholarly) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->scholarly) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->scholarly) (2.0.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->scholarly) (1.7.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from selenium->scholarly) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from selenium->scholarly) (0.11.1)\n",
      "Requirement already satisfied: sphinx<8,>=1.6 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx-rtd-theme->scholarly) (7.2.6)\n",
      "Requirement already satisfied: docutils<0.19 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx-rtd-theme->scholarly) (0.18.1)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx-rtd-theme->scholarly) (4.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx->scholarly) (4.0.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx->scholarly) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cathe\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.7)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.0.4)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.1.9)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.0.6)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.14 in c:\\users\\cathe\\appdata\\roaming\\python\\python310\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.16.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.12.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (0.7.13)\n",
      "Requirement already satisfied: imagesize>=1.3 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21.0 in c:\\users\\cathe\\appdata\\roaming\\python\\python310\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (23.1)\n",
      "Requirement already satisfied: colorama>=0.4.5 in c:\\users\\cathe\\appdata\\roaming\\python\\python310\\site-packages (from sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (0.4.6)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\cathe\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium->scholarly) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio-websocket~=0.9->selenium->scholarly) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium->scholarly) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cathe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Jinja2>=3.0->sphinx<8,>=1.6->sphinx-rtd-theme->scholarly) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install habanero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from bs4 import BeautifulSoup\n",
    "from scholarly import scholarly\n",
    "from scholarly import ProxyGenerator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to OAuth2 credentials JSON file\n",
    "creds_path = r'C:\\Users\\cathe\\practical-data-science-tutorial\\src\\data\\credentials.json'\n",
    "\n",
    "# Define the name of Google Sheet\n",
    "google_sheet_name = 'Fantastic Four altmetric-data-individual'\n",
    "\n",
    "# Define the name of the specific sheet within the Google Sheet\n",
    "specific_sheet_name = 'Health and medical sciences'\n",
    "\n",
    "# Initialize the Google Sheets client\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(creds_path, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet\n",
    "sheet = client.open(google_sheet_name).worksheet(specific_sheet_name)\n",
    "\n",
    "# Get a list of article names from the Google Sheet\n",
    "article_names = sheet.col_values(3)  # Article names are in the third column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Error: local variable 'r' referenced before assignment\n",
      "(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Error: local variable 'r' referenced before assignment\n",
      "(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Error: local variable 'r' referenced before assignment\n",
      "(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Error: local variable 'r' referenced before assignment\n",
      "Citations scraped and updated in the Google Sheet.\n"
     ]
    }
   ],
   "source": [
    "import habanero\n",
    "from habanero import Crossref\n",
    "import pprint\n",
    "\n",
    "# Initialize the Crossref API client\n",
    "cr = Crossref()\n",
    "\n",
    "def get_citation_count(title):\n",
    "    try:\n",
    "        # Search for the paper by title using Crossref API\n",
    "        results = cr.works(query=title)\n",
    "        #pprint.pprint(results)\n",
    "        \n",
    "        # Extract the first result (most relevant) and get the citation count if available\n",
    "        if len(results['message']['items']) > 0:\n",
    "            item = results['message']['items'][0]\n",
    "            citation_count = item.get('is-referenced-by-count', 0)\n",
    "            return citation_count\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Iterate through the article names and scrape citations\n",
    "for i, article_name in enumerate(article_names):\n",
    "    if i == 0:\n",
    "        continue  # Skip the header row\n",
    "\n",
    "    citations = get_citation_count(article_name)\n",
    "    sheet.update_cell(i + 1, 9, citations)  # Store citations in the ninth column\n",
    "\n",
    "print(\"Citations scraped and updated in the Google Sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citations scraped and updated in the Google Sheet.\n"
     ]
    }
   ],
   "source": [
    "# Define the name of the specific sheet within the Google Sheet\n",
    "specific_sheet_name = 'Social sciences'\n",
    "\n",
    "# Open the Google Sheet\n",
    "sheet = client.open(google_sheet_name).worksheet(specific_sheet_name)\n",
    "\n",
    "# Get a list of article names from the Google Sheet\n",
    "article_names = sheet.col_values(3)  # Article names are in the third column\n",
    "\n",
    "# Iterate through the article names and scrape citations\n",
    "for i, article_name in enumerate(article_names):\n",
    "    if i == 0:\n",
    "        continue  # Skip the header row\n",
    "\n",
    "    citations = get_citation_count(article_name)\n",
    "    sheet.update_cell(i + 1, 9, citations)  # Store citations in the ninth column\n",
    "\n",
    "print(\"Citations scraped and updated in the Google Sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Error: local variable 'r' referenced before assignment\n",
      "(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Error: local variable 'r' referenced before assignment\n",
      "(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Error: local variable 'r' referenced before assignment\n",
      "Citations scraped and updated in the Google Sheet.\n"
     ]
    }
   ],
   "source": [
    "# Define the name of the specific sheet within the Google Sheet\n",
    "specific_sheet_name = 'Business, economics and management'\n",
    "\n",
    "# Open the Google Sheet\n",
    "sheet = client.open(google_sheet_name).worksheet(specific_sheet_name)\n",
    "\n",
    "# Get a list of article names from the Google Sheet\n",
    "article_names = sheet.col_values(3)  # Article names are in the third column\n",
    "\n",
    "# Iterate through the article names and scrape citations\n",
    "for i, article_name in enumerate(article_names):\n",
    "    if i == 0:\n",
    "        continue  # Skip the header row\n",
    "\n",
    "    citations = get_citation_count(article_name)\n",
    "    sheet.update_cell(i + 1, 9, citations)  # Store citations in the ninth column\n",
    "\n",
    "print(\"Citations scraped and updated in the Google Sheet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archived Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to scrape citations for an article\n",
    "def scrape_citations(article_name):\n",
    "    try:\n",
    "        pg = ProxyGenerator()\n",
    "        pg.FreeProxies()\n",
    "        scholarly.use_proxy(pg)\n",
    "\n",
    "        # Use the Scholarly library to search for the article by title\n",
    "        search_query = scholarly.search_pubs(article_name)\n",
    "\n",
    "        publication = next(search_query)\n",
    "\n",
    "        # Extract the number of citations\n",
    "        citations = publication['num_citations']\n",
    "\n",
    "        return citations\n",
    "    \n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "# Iterate through the article names and scrape citations\n",
    "for i, article_name in enumerate(article_names):\n",
    "    if i == 0:\n",
    "        continue  # Skip the header row\n",
    "\n",
    "    citations = scrape_citations(article_name)\n",
    "    sheet.update_cell(i + 1, 9, citations)  # Store citations in the ninth column\n",
    "\n",
    "print(\"Citations scraped and updated in the Google Sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cathe\\practical-data-science-tutorial\\src\\data\\scrape_citations.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Skip the header row\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     citations \u001b[39m=\u001b[39m scrape_citations(article_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     sheet\u001b[39m.\u001b[39mupdate_cell(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m9\u001b[39m, citations)  \u001b[39m# Assuming you want to store citations in the ninth column\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Close the Selenium driver\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\cathe\\practical-data-science-tutorial\\src\\data\\scrape_citations.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m search_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://scholar.google.com/scholar?q=\u001b[39m\u001b[39m{\u001b[39;00marticle_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Use Selenium to open the Google Scholar page\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m driver\u001b[39m.\u001b[39;49mget(search_url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Wait for the page to load (you may need to adjust the wait time)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#X45sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m driver\u001b[39m.\u001b[39mimplicitly_wait(\u001b[39m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:353\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m: url})\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:342\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m    340\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[1;32m--> 342\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:297\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    295\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[0;32m    296\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:318\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    315\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 318\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    319\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[0;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\_request_methods.py:118\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    111\u001b[0m         method,\n\u001b[0;32m    112\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw,\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[0;32m    119\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m    120\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\_request_methods.py:217\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    213\u001b[0m     extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m, content_type)\n\u001b[0;32m    215\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, u\u001b[39m.\u001b[39mrequest_uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the path to your OAuth2 credentials JSON file\n",
    "creds_path = r'C:\\Users\\cathe\\practical-data-science-tutorial\\src\\data\\credentials.json'\n",
    "\n",
    "# Define the name of your Google Sheet\n",
    "google_sheet_name = 'Fantastic Four altmetric-data-individual'\n",
    "\n",
    "# Define the name of the specific sheet within the Google Sheet\n",
    "specific_sheet_name = 'Health and medical sciences'\n",
    "\n",
    "# Initialize the Google Sheets client\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(creds_path, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet\n",
    "sheet = client.open(google_sheet_name).worksheet(specific_sheet_name)\n",
    "\n",
    "# Get a list of article names from the Google Sheet\n",
    "article_names = sheet.col_values(3)  # Assuming article names are in the third column\n",
    "\n",
    "# Configure Selenium to run a headless browser\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Create a function to scrape citations for an article\n",
    "def scrape_citations(article_name):\n",
    "    try:\n",
    "        # Construct a Google Scholar search URL\n",
    "        search_url = f'https://scholar.google.com/scholar?q={article_name}'\n",
    "\n",
    "        # Use Selenium to open the Google Scholar page\n",
    "        driver.get(search_url)\n",
    "\n",
    "        # Wait for the page to load (you may need to adjust the wait time)\n",
    "        driver.implicitly_wait(5)\n",
    "\n",
    "        # Parse the HTML response using BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Extract the number of citations (assuming it's in a specific class)\n",
    "        citations_text = soup.find('div', class_='gs_fl gs_flb')\n",
    "        citations_element = citations_text.find('a', string=lambda text: text and \"Cited by\" in text)\n",
    "\n",
    "        if citations_element:\n",
    "            citations = int(citations_element.text.split(' ')[-1])\n",
    "        else:\n",
    "            citations = None  # Handle the case when the information is not found\n",
    "\n",
    "        return citations\n",
    "    \n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Iterate through the article names and scrape citations\n",
    "for i, article_name in enumerate(article_names):\n",
    "    if i == 0:\n",
    "        continue  # Skip the header row\n",
    "    citations = scrape_citations(article_name)\n",
    "    sheet.update_cell(i + 1, 9, citations)  # Assuming you want to store citations in the ninth column\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Citations scraped and updated in the Google Sheet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"ext\">Extract this tag</div>\n"
     ]
    }
   ],
   "source": [
    "HTML_DOC = \"\"\"\n",
    "              <html>\n",
    "               <head>\n",
    "                   <title> Geeksforgeeks </title>\n",
    "               </head>\n",
    "               <body>\n",
    "                   <div class=\"ext\" >Extract this tag</div>\n",
    "               </body>\n",
    "             </html>\n",
    "            \"\"\"\n",
    " \n",
    "# Function to find tags\n",
    "def find_tags_from_class(html):\n",
    " \n",
    "    # parse html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    " \n",
    "    # find tags by CSS class\n",
    "    div = soup.find(\"div\", class_= \"ext\")\n",
    " \n",
    "    # Print the extracted tag\n",
    "    print(div)\n",
    " \n",
    "# Function Call\n",
    "find_tags_from_class(HTML_DOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"gfg-stc\" href=\"#main\" style=\"top:0\">Skip to content</a>\n",
      "<a href=\"https://www.geeksforgeeks.org/courses/dsa-to-development-coding-guide?itm_source=geeksforgeeks&amp;itm_medium=main_header&amp;itm_campaign=courses\" target=\"_self\">DSA to Development</a>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    " \n",
    "# sample website\n",
    "sample_website = 'https://www.geeksforgeeks.org/different-ways-to-remove-all-the-digits-from-string-in-java/'\n",
    " \n",
    "# call get method to request the page\n",
    "page = requests.get(sample_website)\n",
    " \n",
    "# with the help of BeautifulSoup method and\n",
    "# html parser created soup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    " \n",
    "#With the help of . operator we will scrap a\n",
    "# tag under body->a\n",
    "# here we will go a tag inside body then a then\n",
    "# li.means under the body tag we will go to a tag \n",
    "print(soup.body.a)\n",
    " \n",
    "# With the help of . operator we will scrap a\n",
    "# tag under body->ui->li\n",
    "# here we will go a tag inside body then ul then\n",
    "# li.means under the body tag we will go to ul tag\n",
    "# and again inside the ul tag we will go li tag\n",
    "# and inside to li tag we will go to a tag\n",
    "print(soup.body.ul.li.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 class=\"tabtitle\">Java</h2>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('h2', {'class': 'tabtitle'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = 'https://scholar.google.com/scholar?q=The%20psychological%20impact%20of%20quarantine%20and%20how%20to%20reduce%20it:%20rapid%20review%20of%20the%20evidence'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "response = requests.get(search_url, headers = headers)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML content saved to 'output.html'\n"
     ]
    }
   ],
   "source": [
    "# Convert the BeautifulSoup object to a string\n",
    "html_string = soup.prettify()\n",
    "\n",
    "# Save the HTML content to a file\n",
    "with open('output.html', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(html_string)\n",
    "\n",
    "print(\"HTML content saved to 'output.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"#\" onclick=\"document.getElementById('infoDiv').style.display='block';\">Why did this happen?</a>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('a', href = \"#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>About this page</b>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('div', class_ = 'gs_fl gs_flb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/>\n",
      "  <meta content=\"initial-scale=1\" name=\"viewport\"/>\n",
      "  <title>\n",
      "   https://scholar.google.com/scholar?q=The%20psychological%20impact%20of%20quarantine%20and%20how%20to%20reduce%20it:%20rapid%20review%20of%20the%20evidence\n",
      "  </title>\n",
      " </head>\n",
      " <body onload=\"e=document.getElementById('captcha');if(e){e.focus();} if(solveSimpleChallenge) {solveSimpleChallenge(,);}\" style=\"font-family: arial, sans-serif; background-color: #fff; color: #000; padding:20px; font-size:18px; overscroll-behavior:contain;\">\n",
      "  <div style=\"max-width:400px;\">\n",
      "   <hr noshade=\"\" size=\"1\" style=\"color:#ccc; background-color:#ccc;\"/>\n",
      "   <br/>\n",
      "   <form action=\"index\" id=\"captcha-form\" method=\"post\">\n",
      "    <noscript>\n",
      "     <div style=\"font-size:13px;\">\n",
      "      In order to continue, please enable javascript on your web browser.\n",
      "     </div>\n",
      "    </noscript>\n",
      "    <script async=\"\" defer=\"\" src=\"https://www.google.com/recaptcha/api.js\">\n",
      "    </script>\n",
      "    <script>\n",
      "     var submitCallback = function(response) {document.getElementById('captcha-form').submit();};\n",
      "    </script>\n",
      "    <div class=\"g-recaptcha\" data-callback=\"submitCallback\" data-s=\"Z063b4w53Aoht87Cl-FF6OGbwvcYvNKazftEPIA27hq6LlPEcy2g2Bj0rici7SpWqzKGCFCpS3xQwETzWTTGalyhqRz8jOfXN8pa9icx8ohzL-ldutt-0BXKehTnyVNClvl0KpG1K7nFrM0lNKNNbZYEuIMnTCsKCeNgQdwtIu0TbnxaCtiBv0GZuEnHh1jVPw6_Via8LKhuTgQfvwRrki4yv6MZns1-3hqjYvEvrrT8CXZ7_7Q7lfsYTBnT4l4bXrwkWx81n6YD4voRk7oNPNR4\" data-sitekey=\"6LfwuyUTAAAAAOAmoS0fdqijC2PbbdH4kjq62Y1b\" id=\"recaptcha\">\n",
      "    </div>\n",
      "    <input name=\"q\" type=\"hidden\" value=\"EgTTSOyRGM-T6qgGIixBIAG6PfCz7RXBV0syv_CHimwsN3ZnW5TKXhanwtK1isRm7l86Xcbb791pZjIBcloBQw\"/>\n",
      "    <input name=\"continue\" type=\"hidden\" value=\"https://scholar.google.com/scholar?q=The%20psychological%20impact%20of%20quarantine%20and%20how%20to%20reduce%20it:%20rapid%20review%20of%20the%20evidence\"/>\n",
      "   </form>\n",
      "   <hr noshade=\"\" size=\"1\" style=\"color:#ccc; background-color:#ccc;\"/>\n",
      "   <div style=\"font-size:13px;\">\n",
      "    <b>\n",
      "     About this page\n",
      "    </b>\n",
      "    <br/>\n",
      "    <br/>\n",
      "    Our systems have detected unusual traffic from your computer network.  This page checks to see if it's really you sending the requests, and not a robot.\n",
      "    <a href=\"#\" onclick=\"document.getElementById('infoDiv').style.display='block';\">\n",
      "     Why did this happen?\n",
      "    </a>\n",
      "    <br/>\n",
      "    <br/>\n",
      "    <div id=\"infoDiv\" style=\"display:none; background-color:#eee; padding:10px; margin:0 0 15px 0; line-height:1.4em;\">\n",
      "     This page appears when Google automatically detects requests coming from your computer network which appear to be in violation of the\n",
      "     <a href=\"//www.google.com/policies/terms/\">\n",
      "      Terms of Service\n",
      "     </a>\n",
      "     . The block will expire shortly after those requests stop.  In the meantime, solving the above CAPTCHA will let you continue to use our services.\n",
      "     <br/>\n",
      "     <br/>\n",
      "     This traffic may have been sent by malicious software, a browser plug-in, or a script that sends automated requests.  If you share your network connection, ask your administrator for help  a different computer using the same IP address may be responsible.\n",
      "     <a href=\"//support.google.com/websearch/answer/86640\">\n",
      "      Learn more\n",
      "     </a>\n",
      "     <br/>\n",
      "     <br/>\n",
      "     Sometimes you may be asked to solve the CAPTCHA if you are using advanced terms that robots are known to use, or sending requests very quickly.\n",
      "    </div>\n",
      "    IP address: 211.72.236.145\n",
      "    <br/>\n",
      "    Time: 2023-10-02T09:13:52Z\n",
      "    <br/>\n",
      "    URL: https://scholar.google.com/scholar?q=The%20psychological%20impact%20of%20quarantine%20and%20how%20to%20reduce%20it:%20rapid%20review%20of%20the%20evidence\n",
      "    <br/>\n",
      "   </div>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 'Cited by' not found in the document.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cathe\\AppData\\Local\\Temp\\ipykernel_21096\\773410186.py:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  citation_text = soup.find(text='Cited by')\n"
     ]
    }
   ],
   "source": [
    "# Find the first occurrence of 'Cited by'\n",
    "citation_text = soup.find(text='Cited by')\n",
    "\n",
    "if citation_text:\n",
    "    # Extract the number that comes after 'Cited by'\n",
    "    number = citation_text.find_next()\n",
    "    print(number)\n",
    "else:\n",
    "    print(\"Text 'Cited by' not found in the document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citations_text: None\n",
      "citations_text: None\n",
      "citations_text: None\n",
      "citations_text: None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cathe\\practical-data-science-tutorial\\src\\data\\scrape_citations.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Skip the header row\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     citations \u001b[39m=\u001b[39m scrape_citations(article_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     sheet\u001b[39m.\u001b[39mupdate_cell(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m9\u001b[39m, citations)  \u001b[39m# Assuming you want to store citations in the ninth column\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCitations scraped and updated in the Google Sheet.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\cathe\\practical-data-science-tutorial\\src\\data\\scrape_citations.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m search_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://scholar.google.com/scholar?q=\u001b[39m\u001b[39m{\u001b[39;00marticle_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Send an HTTP GET request to the search URL\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(search_url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Parse the HTML response using BeautifulSoup\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cathe/practical-data-science-tutorial/src/data/scrape_citations.ipynb#W1sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    468\u001b[0m     \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[0;32m   1095\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1096\u001b[0m         (\n\u001b[0;32m   1097\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconn\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1102\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1103\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    610\u001b[0m     sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    612\u001b[0m     server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m    613\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[39m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[0;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[0;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[0;32m    208\u001b[0m     )\n\u001b[0;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Define the path to your OAuth2 credentials JSON file\n",
    "creds_path = r'C:\\Users\\cathe\\practical-data-science-tutorial\\src\\data\\credentials.json'\n",
    "\n",
    "# Define the name of your Google Sheet\n",
    "google_sheet_name = 'Fantastic Four altmetric-data-individual'\n",
    "\n",
    "# Define the name of the specific sheet within the Google Sheet\n",
    "specific_sheet_name = 'Health and medical sciences'\n",
    "\n",
    "# Initialize the Google Sheets client\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(creds_path, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet\n",
    "sheet = client.open(google_sheet_name).worksheet(specific_sheet_name)\n",
    "\n",
    "# Get a list of article names from the Google Sheet\n",
    "article_names = sheet.col_values(3)  # Assuming article names are in the third column\n",
    "\n",
    "# Create a function to scrape citations for an article\n",
    "def scrape_citations(article_name):\n",
    "    try:\n",
    "        # Construct a Google Scholar search URL\n",
    "        search_url = f'https://scholar.google.com/scholar?q={article_name}'\n",
    "\n",
    "        # Send an HTTP GET request to the search URL\n",
    "        response = requests.get(search_url)\n",
    "\n",
    "        # Parse the HTML response using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract the number of citations (assuming it's in a specific class)\n",
    "        citations_text = soup.find('div', class_='gs_fl gs_flb')\n",
    "        citations_element = citations_text.find('a', string=lambda text: text and \"Cited by\" in text)\n",
    "\n",
    "        if citations_element:\n",
    "            citations = int(citations_element.text.split(' ')[-1])\n",
    "        else:\n",
    "            citations = None  # Handle the case when the information is not found\n",
    "\n",
    "        return citations\n",
    "    \n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Iterate through the article names and scrape citations\n",
    "for i, article_name in enumerate(article_names):\n",
    "    if i == 0:\n",
    "        continue  # Skip the header row\n",
    "    citations = scrape_citations(article_name)\n",
    "    sheet.update_cell(i + 1, 9, citations)  # Assuming you want to store citations in the ninth column\n",
    "\n",
    "print(\"Citations scraped and updated in the Google Sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
