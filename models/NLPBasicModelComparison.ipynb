{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Paper Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to OAuth2 credentials JSON file\n",
    "creds_path = r'C:\\Users\\cathe\\practical-data-science-tutorial\\src\\data\\credentials.json'\n",
    "\n",
    "# Define the name of Google Sheet\n",
    "google_sheet_name = 'Draft-dataset'\n",
    "\n",
    "# Define the name of the specific sheet within the Google Sheet\n",
    "specific_sheet_names = ['Health and medical sciences', 'Social sciences', 'Business, economics and management']\n",
    "\n",
    "# Initialize the Google Sheets client\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(creds_path, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "papers_unlabelled = []\n",
    "\n",
    "for specific_sheet_name in specific_sheet_names:\n",
    "    # Open the Google Sheet\n",
    "    sheet = client.open(google_sheet_name).worksheet(specific_sheet_name)\n",
    "\n",
    "    # Get list of article names from the sheet\n",
    "    papers = sheet.col_values(3)[1:]\n",
    "\n",
    "    # Add all article names to a single list\n",
    "    papers_unlabelled.extend(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The psychological impact of quarantine and how to reduce it: rapid review of the evidence',\n",
       " 'Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990â€“2017: a systematic analysis for the Global Burden of Disease Study 2017',\n",
       " 'A novel coronavirus outbreak of global health concern']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_unlabelled[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of Google Sheet\n",
    "google_sheet_name = 'Draft-dataset'\n",
    "\n",
    "# Define the name of the specific sheet within the Google Sheet\n",
    "specific_sheet_name = 'Copy of finaldataset'\n",
    "\n",
    "# Initialize the Google Sheets client\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(creds_path, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet\n",
    "sheet = client.open(google_sheet_name).worksheet(specific_sheet_name)\n",
    "\n",
    "# Get list of article names & labels from the sheet\n",
    "papers_labelled = sheet.col_values(3)[1:]\n",
    "labels = sheet.col_values(15)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [int(float(i)) for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['COVID-19: the gendered impacts of the outbreak',\n",
       "  'COVID-19: towards controlling of a pandemic',\n",
       "  'Prevention and treatment of low back pain: evidence, challenges, and promising directions'],\n",
       " [3, 1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_labelled[:3], labels[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\cathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK data for stopwords and lemmatisation\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Define stopwords to remove\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['covid19', 'sarscov2'])\n",
    "\n",
    "# Initialize lemmatiser\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Map POS tags to WordNet tags for lemmatisation\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def preprocess_title(title):\n",
    "    # Remove non-alphanumeric characters\n",
    "    title_alpha = re.sub(r'[^a-zA-Z0-9\\s]', '', title)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    title_lower = title_alpha.lower()\n",
    "\n",
    "    # Break down into individual words\n",
    "    words = word_tokenize(title_lower)\n",
    "\n",
    "    # Remove stopwords\n",
    "    # words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Part-of-Speech (POS) tagging\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    # Remove words that are nouns (NN, NNS, NNP, NNPS)\n",
    "    non_noun_words = [word for word, pos in tagged_words if not pos.startswith('N')]\n",
    "\n",
    "    # Lemmatisation of words & removal of words that aren't adjectives/verbs/adverbs\n",
    "    lemmatised_words = [lemmatizer.lemmatize(word) for word in non_noun_words]\n",
    "\n",
    "    return lemmatised_words\n",
    "\n",
    "# Apply preprocessing to all titles\n",
    "papers_labelled_processed = [preprocess_title(title) for title in papers_labelled]\n",
    "papers_unlabelled_processed = [preprocess_title(title) for title in papers_unlabelled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['covid19', 'the', 'gendered', 'of', 'the'],\n",
       " ['controlling', 'of', 'a', 'pandemic'],\n",
       " ['and', 'of', 'low', 'back', 'and', 'promising']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_labelled_processed[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'psychological',\n",
       "  'of',\n",
       "  'and',\n",
       "  'how',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'it',\n",
       "  'rapid',\n",
       "  'of',\n",
       "  'the'],\n",
       " ['global',\n",
       "  'regional',\n",
       "  'and',\n",
       "  'national',\n",
       "  'and',\n",
       "  'lived',\n",
       "  'with',\n",
       "  'for',\n",
       "  '354',\n",
       "  'and',\n",
       "  'for',\n",
       "  '195',\n",
       "  'and',\n",
       "  '19902017',\n",
       "  'a',\n",
       "  'systematic',\n",
       "  'for',\n",
       "  'the',\n",
       "  'global',\n",
       "  'of',\n",
       "  '2017'],\n",
       " ['a', 'novel', 'of', 'global']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_unlabelled_processed[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on preprocessed titles and transform them into a BoW representation\n",
    "labelled_bow = vectorizer.fit_transform([\" \".join(title) for title in papers_labelled_processed])\n",
    "\n",
    "# Store the vocabulary used for creating BoW representations\n",
    "vocabulary = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x288 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 623 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer(vocabulary=vocabulary)\n",
    "\n",
    "# Fit the vectorizer on preprocessed titles and transform them into a BoW representation\n",
    "unlabelled_bow = vectorizer.fit_transform([\" \".join(title) for title in papers_unlabelled_processed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1242x288 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5290 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 30, 'n_estimators': 100}\n",
      "Validation weighted F1: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(labelled_bow, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a range of hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 1, 2, 3, 5, 8, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='f1_weighted')\n",
    "\n",
    "# Fit the model to find the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the validation set using the best model\n",
    "y_pred = best_rf_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print(f\"Validation weighted F1: {f1}\")\n",
    "\n",
    "# Predict labels for unlabelled data using the best model\n",
    "predicted_scores = best_rf_model.predict(unlabelled_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with params {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} - Cross-Validation F1 score: 0.49515695415695404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "60 fits failed out of a total of 225.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1228, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.39367853 0.39367853 0.36225071 0.36648926 0.36648926        nan\n",
      "        nan 0.22857143        nan 0.22857143 0.35266312 0.387513\n",
      "        nan 0.36515023 0.38163895 0.43289198 0.43289198 0.43800031\n",
      " 0.4220663  0.41192064        nan        nan 0.46252507        nan\n",
      " 0.46560197 0.35266312 0.387513          nan 0.36515023 0.38163895\n",
      " 0.41106663 0.41106663 0.43076937 0.37935146 0.37935146        nan\n",
      "        nan 0.40839273        nan 0.41044581 0.35266312 0.387513\n",
      "        nan 0.36515023 0.38163895]\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with params {'C': 1, 'penalty': 'l1', 'solver': 'saga'} - Cross-Validation F1 score: 0.46560196935025316\n",
      "SVM with params {'C': 10, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'} - Cross-Validation F1 score: 0.46521109523431503\n",
      "K-Nearest Neighbors with params {'n_neighbors': 9, 'weights': 'uniform'} - Cross-Validation F1 score: 0.34913793396146336\n",
      "Decision Tree with params {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5} - Cross-Validation F1 score: 0.5644094173800056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "60 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 775, in fit\n",
      "    self._update_class_log_prior(class_prior=class_prior)\n",
      "  File \"c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 590, in _update_class_log_prior\n",
      "    raise ValueError(\"Number of priors must match number of classes.\")\n",
      "ValueError: Number of priors must match number of classes.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.3331384  0.28457376        nan        nan        nan        nan\n",
      " 0.36118894 0.38486003        nan        nan        nan        nan\n",
      " 0.4036042  0.3879243         nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes with params {'alpha': 1.0, 'class_prior': None, 'fit_prior': True} - Cross-Validation F1 score: 0.40360420037478867\n",
      "Gradient Boosting with params {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200} - Cross-Validation F1 score: 0.5147668399114085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network with params {'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate_init': 0.001, 'solver': 'sgd'} - Cross-Validation F1 score: 0.4694112643462489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the range of hyperparameters for each model\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l2', 'l1', None],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'], \n",
    "    'degree': [3, 4, 5] \n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 1, 2, 3, 5, 8, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_nb = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'fit_prior': [True, False],\n",
    "    'class_prior': [None, [0.2, 0.8], [0.5, 0.5]]\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "param_grid_nn = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100, 100), (50, 100, 50)],\n",
    "    'alpha': [0.0001, 0.0005, 0.001],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), param_grid_rf),\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42), param_grid_lr),\n",
    "    'SVM': (SVC(random_state=42), param_grid_svm),\n",
    "    'K-Nearest Neighbors': (KNeighborsClassifier(), param_grid_knn),\n",
    "    'Decision Tree': (DecisionTreeClassifier(random_state=42), param_grid_dt),\n",
    "    'Multinomial Naive Bayes': (MultinomialNB(), param_grid_nb),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(random_state=42), param_grid_gb),\n",
    "    'Neural Network': (MLPClassifier(random_state=42, max_iter=1000), param_grid_nn)\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    # Perform grid search with 5-fold cross-validation using F1 score as the scoring metric\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1_weighted')\n",
    "\n",
    "    # Fit the model to find the best hyperparameters\n",
    "    grid_search.fit(labelled_bow, labels)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[model_name] = best_model\n",
    "\n",
    "    # Calculate F1 score using cross-validation\n",
    "    cv_scores = cross_val_score(best_model, labelled_bow, labels, cv=5, scoring='f1_weighted')\n",
    "    print(f\"{model_name} with params {best_params} - Cross-Validation F1 score: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Select the best model based on the mean cross-validation F1 score\n",
    "best_model_name = max(best_models, key=lambda x: np.mean(cross_val_score(best_models[x], labelled_bow, labels, cv=5, scoring='f1_weighted')))\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"The best model is: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the best model to the entire training dataset\n",
    "#best_model.fit(labelled_bow, labels)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y_pred = best_model.predict(labelled_bow)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, y_pred)\n",
    "\n",
    "# Define class names\n",
    "class_names = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Plot the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Weighted): 0.9149683883641728\n",
      "Precision (Micro): 0.92\n",
      "Precision (Weighted): 0.9266852226720647\n",
      "Recall (Micro): 0.92\n",
      "Recall (Weighted): 0.92\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(labels, y_pred)\n",
    "\n",
    "# Calculate F1 score (micro, weighted, or other averaging methods)\n",
    "f1_micro = f1_score(labels, y_pred, average='micro')\n",
    "f1_weighted = f1_score(labels, y_pred, average='weighted')\n",
    "\n",
    "# Calculate precision (micro, weighted, or other averaging methods)\n",
    "precision_micro = precision_score(labels, y_pred, average='micro')\n",
    "precision_weighted = precision_score(labels, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall (micro, weighted, or other averaging methods)\n",
    "recall_micro = recall_score(labels, y_pred, average='micro')\n",
    "recall_weighted = recall_score(labels, y_pred, average='weighted')\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score (Micro): {f1_micro}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted}\")\n",
    "print(f\"Precision (Micro): {precision_micro}\")\n",
    "print(f\"Precision (Weighted): {precision_weighted}\")\n",
    "print(f\"Recall (Micro): {recall_micro}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for unlabelled data using the best model\n",
    "predicted_scores = best_model.predict(unlabelled_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The psychological impact of quarantine and how to reduce it: rapid review of the evidence',\n",
       "  'Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990â€“2017: a systematic analysis for the Global Burden of Disease Study 2017',\n",
       "  'A novel coronavirus outbreak of global health concern'],\n",
       " array([3, 2, 1]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_unlabelled[:3], predicted_scores[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
